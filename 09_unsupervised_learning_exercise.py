# -*- coding: utf-8 -*-
"""09 - unsupervised_learning_exercise.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rSV6UX2M1gb9LIN0HfcgCq7i7vJVP2mi

# Cluster the Olivetti Faces Dataset

O clássico conjunto de dados Olivetti contém 400 imagens de rostos em escala de cixa de $64 \times 64$. Cada imagem é achatada para um vetor 1D de tamanho 4.096. Quarenta pessoas diferentes foram fotografadas (dez de cada vez). A tarefa é treinar um modelo que possa predizer qual pessoa é representada em cada foto.
1) Carregue o conjunto de dados usando e o divida em conjunto de treino,teste e validação.
2) Como o conjunto é muito pequeno, utilize amostragem estratificada para garantir que haja o mesmo número de imagens por pessoa.
3) Clusterize o conjunto usando o Kmeans e selecione o número de clusters de acordo com o coeficiente de silhueta.
4) Treine um modelo de mistura guassiana com os mesmos dados. Empregue o modelo para gerar novos rostos usando o método sample()
"""

from sklearn.datasets import fetch_olivetti_faces
olivetti = fetch_olivetti_faces()

print(olivetti.DESCR)

olivetti.target

from sklearn.model_selection import StratifiedShuffleSplit
strat_split = StratifiedShuffleSplit(n_splits=1, test_size=40, random_state=42)
train_idx, _ = next(strat_split.split(olivetti.data, olivetti.target))
X_train = olivetti.data[train_idx]
y_train = olivetti.target[train_idx]

print(X_train.shape, y_train.shape)

from sklearn.decomposition import PCA
pca = PCA(0.99)
X_train_pca = pca.fit_transform(X_train)

pca.n_components_

from sklearn.cluster import KMeans
k_range = range(5,150,5)
kmeans_per_k = []
for k in k_range:
    print(f"k={k}")
    kmeans = KMeans(n_clusters=k, random_state=42).fit(X_train_pca)
    kmeans_per_k.append(kmeans)

from sklearn.metrics import silhouette_score
import numpy as np
import matplotlib.pyplot as plt

silhouette_scores = [silhouette_score(X_train_pca, model.labels_)
                     for model in kmeans_per_k]
best_index = np.argmax(silhouette_scores)
best_k = k_range[best_index]
best_socore = silhouette_scores[best_index]

plt.figure(figsize=(8,3))
plt.plot(k_range, silhouette_scores, "bo-")
plt.xlabel("$k$", fontsize=14)
plt.ylabel("silhouette score", fontsize=14)
plt.plot(best_k, best_socore, "rs")
plt.show()

best_k

best_model = kmeans_per_k[best_index]

# function to plot faces
def plot_faces(faces, labels, n_cols=5):
    faces = faces.reshape(-1,64,64)
    n_rows = (len(faces) - 1) // n_cols + 1
    plt.figure(figsize=(n_cols, n_rows * 1.1))
    for index, (face, label) in enumerate(zip(faces, labels)):
        plt.subplot(n_rows, n_cols, index + 1)
        plt.imshow(face, cmap="gray")
        plt.axis("off")
        plt.title(label)
    plt.show()

for cluster_id in np.unique(best_model.labels_):
    print("cluster", cluster_id)
    in_cluster = best_model.labels_==cluster_id
    faces = X_train[in_cluster]
    labels = y_train[in_cluster]
    plot_faces(faces, labels)

from sklearn.mixture import GaussianMixture
gm = GaussianMixture(n_components = 40, random_state=42)
y_pred = gm.fit_predict(X_train_pca)

n_gen_faces = 20
gen_faces_reduced, y_gen_faces = gm.sample(n_samples=n_gen_faces)
gen_faces = pca.inverse_transform(gen_faces_reduced)

plot_faces(gen_faces, y_gen_faces)

